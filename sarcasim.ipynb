{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "T-SrWDK23-Q-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "2DycQVKv4BAV"
      },
      "outputs": [],
      "source": [
        "json_sarcastic_file = requests.get(\"https://storage.googleapis.com/learning-datasets/sarcasm.json\")\n",
        "sarcasm_data = json_sarcastic_file.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sssWgwTL_7VH",
        "outputId": "9dbdd04e-f208-4aae-99d0-62a60912b647"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(26709, list)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(sarcasm_data), type(sarcasm_data),"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OANV3qbUAIg3",
        "outputId": "4234d9b1-ebde-4f86-9dd3-c0a1fd4ce0ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'article_link': 'https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5',\n",
              "  'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\",\n",
              "  'is_sarcastic': 0},\n",
              " {'article_link': 'https://www.huffingtonpost.com/entry/roseanne-revival-review_us_5ab3a497e4b054d118e04365',\n",
              "  'headline': \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\",\n",
              "  'is_sarcastic': 0},\n",
              " {'article_link': 'https://local.theonion.com/mom-starting-to-fear-son-s-web-series-closest-thing-she-1819576697',\n",
              "  'headline': \"mom starting to fear son's web series closest thing she will have to grandchild\",\n",
              "  'is_sarcastic': 1},\n",
              " {'article_link': 'https://politics.theonion.com/boehner-just-wants-wife-to-listen-not-come-up-with-alt-1819574302',\n",
              "  'headline': 'boehner just wants wife to listen, not come up with alternative debt-reduction ideas',\n",
              "  'is_sarcastic': 1},\n",
              " {'article_link': 'https://www.huffingtonpost.com/entry/jk-rowling-wishes-snape-happy-birthday_us_569117c4e4b0cad15e64fdcb',\n",
              "  'headline': 'j.k. rowling wishes snape happy birthday in the most magical way',\n",
              "  'is_sarcastic': 0}]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sarcasm_data[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "GrAlMN9lAUK2"
      },
      "outputs": [],
      "source": [
        "sarcastic_sentences = []\n",
        "is_sarcastic_lbl = []\n",
        "article_links = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "YoKocRrWAku8"
      },
      "outputs": [],
      "source": [
        "for item in sarcasm_data:\n",
        "  sarcastic_sentences.append(item[\"headline\"])\n",
        "  is_sarcastic_lbl.append(item[\"is_sarcastic\"])\n",
        "  article_links.append(item[\"article_link\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "-oh1Zky8Bi6f"
      },
      "outputs": [],
      "source": [
        "TRAINING_SIZE = 20000\n",
        "VOCAB_SIZE = 10000\n",
        "OOV_TOK = \"<OOV>\"\n",
        "MAX_LENGTH = 100\n",
        "TRUNC_TYPE = \"post\"\n",
        "PADDING_TYPE = \"post\"\n",
        "EMBEDDING_DIM = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "4emWMUDnCDh-"
      },
      "outputs": [],
      "source": [
        "training_sentences = sarcastic_sentences[:TRAINING_SIZE]\n",
        "testing_sentences = sarcastic_sentences[TRAINING_SIZE:]\n",
        "training_lbls = is_sarcastic_lbl[:TRAINING_SIZE]\n",
        "testing_lbls = is_sarcastic_lbl[TRAINING_SIZE:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "cfazLea8Ck4Q"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=OOV_TOK)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=MAX_LENGTH,\n",
        "                                padding=PADDING_TYPE, truncating=TRUNC_TYPE)\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=MAX_LENGTH,\n",
        "                               padding=PADDING_TYPE, truncating=TRUNC_TYPE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBFJ9T_bGMu7",
        "outputId": "6093c5bc-0afa-48ae-88cb-cea023ae9bcf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[   1, 1100, 6663, ...,    0,    0,    0],\n",
              "        [ 202,    1,    8, ...,    0,    0,    0],\n",
              "        [  18,  380,  191, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [   1,    9,   67, ...,    0,    0,    0],\n",
              "        [1556,  374, 4114, ...,    0,    0,    0],\n",
              "        [   1, 1700,    6, ...,    0,    0,    0]], dtype=int32),\n",
              " array([[ 328,    1,  799, ...,    0,    0,    0],\n",
              "        [   4, 6840, 3096, ...,    0,    0,    0],\n",
              "        [ 153,  890,    2, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [  79, 1729,    1, ...,    0,    0,    0],\n",
              "        [  53, 5108, 4735, ...,    0,    0,    0],\n",
              "        [ 312,  705,    1, ...,    0,    0,    0]], dtype=int32))"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testing_padded, training_padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "zkSUXGiuNid_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "training_padded = np.array(training_padded)\n",
        "training_labels = np.array(training_lbls)\n",
        "testing_padded = np.array(testing_padded)\n",
        "testing_labels = np.array(testing_lbls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "liUZY4OeARRs"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(24, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPK5aV2f40yQ",
        "outputId": "f63db192-93a6-4546-d255-a7c4dea97e43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "625/625 - 25s - loss: 0.6703 - accuracy: 0.5771 - val_loss: 0.6000 - val_accuracy: 0.6330 - 25s/epoch - 40ms/step\n",
            "Epoch 2/30\n",
            "625/625 - 3s - loss: 0.4390 - accuracy: 0.8246 - val_loss: 0.3837 - val_accuracy: 0.8402 - 3s/epoch - 5ms/step\n",
            "Epoch 3/30\n",
            "625/625 - 3s - loss: 0.3119 - accuracy: 0.8760 - val_loss: 0.3552 - val_accuracy: 0.8474 - 3s/epoch - 5ms/step\n",
            "Epoch 4/30\n",
            "625/625 - 3s - loss: 0.2607 - accuracy: 0.8972 - val_loss: 0.3424 - val_accuracy: 0.8521 - 3s/epoch - 5ms/step\n",
            "Epoch 5/30\n",
            "625/625 - 3s - loss: 0.2232 - accuracy: 0.9133 - val_loss: 0.3417 - val_accuracy: 0.8556 - 3s/epoch - 4ms/step\n",
            "Epoch 6/30\n",
            "625/625 - 3s - loss: 0.1950 - accuracy: 0.9260 - val_loss: 0.3622 - val_accuracy: 0.8509 - 3s/epoch - 5ms/step\n",
            "Epoch 7/30\n",
            "625/625 - 3s - loss: 0.1730 - accuracy: 0.9362 - val_loss: 0.3635 - val_accuracy: 0.8538 - 3s/epoch - 4ms/step\n",
            "Epoch 8/30\n",
            "625/625 - 3s - loss: 0.1547 - accuracy: 0.9430 - val_loss: 0.3793 - val_accuracy: 0.8533 - 3s/epoch - 4ms/step\n",
            "Epoch 9/30\n",
            "625/625 - 3s - loss: 0.1379 - accuracy: 0.9505 - val_loss: 0.3977 - val_accuracy: 0.8505 - 3s/epoch - 5ms/step\n",
            "Epoch 10/30\n",
            "625/625 - 2s - loss: 0.1246 - accuracy: 0.9572 - val_loss: 0.4206 - val_accuracy: 0.8480 - 2s/epoch - 3ms/step\n",
            "Epoch 11/30\n",
            "625/625 - 2s - loss: 0.1121 - accuracy: 0.9617 - val_loss: 0.4419 - val_accuracy: 0.8462 - 2s/epoch - 3ms/step\n",
            "Epoch 12/30\n",
            "625/625 - 2s - loss: 0.1043 - accuracy: 0.9643 - val_loss: 0.4757 - val_accuracy: 0.8410 - 2s/epoch - 3ms/step\n",
            "Epoch 13/30\n",
            "625/625 - 2s - loss: 0.0928 - accuracy: 0.9699 - val_loss: 0.4916 - val_accuracy: 0.8433 - 2s/epoch - 4ms/step\n",
            "Epoch 14/30\n",
            "625/625 - 3s - loss: 0.0852 - accuracy: 0.9722 - val_loss: 0.5356 - val_accuracy: 0.8380 - 3s/epoch - 5ms/step\n",
            "Epoch 15/30\n",
            "625/625 - 3s - loss: 0.0787 - accuracy: 0.9740 - val_loss: 0.5617 - val_accuracy: 0.8346 - 3s/epoch - 4ms/step\n",
            "Epoch 16/30\n",
            "625/625 - 2s - loss: 0.0711 - accuracy: 0.9769 - val_loss: 0.5811 - val_accuracy: 0.8362 - 2s/epoch - 4ms/step\n",
            "Epoch 17/30\n",
            "625/625 - 2s - loss: 0.0647 - accuracy: 0.9800 - val_loss: 0.6076 - val_accuracy: 0.8326 - 2s/epoch - 4ms/step\n",
            "Epoch 18/30\n",
            "625/625 - 2s - loss: 0.0609 - accuracy: 0.9799 - val_loss: 0.6344 - val_accuracy: 0.8329 - 2s/epoch - 4ms/step\n",
            "Epoch 19/30\n",
            "625/625 - 2s - loss: 0.0573 - accuracy: 0.9821 - val_loss: 0.6662 - val_accuracy: 0.8302 - 2s/epoch - 4ms/step\n",
            "Epoch 20/30\n",
            "625/625 - 3s - loss: 0.0501 - accuracy: 0.9854 - val_loss: 0.6951 - val_accuracy: 0.8302 - 3s/epoch - 5ms/step\n",
            "Epoch 21/30\n",
            "625/625 - 2s - loss: 0.0480 - accuracy: 0.9861 - val_loss: 0.7282 - val_accuracy: 0.8274 - 2s/epoch - 4ms/step\n",
            "Epoch 22/30\n",
            "625/625 - 2s - loss: 0.0425 - accuracy: 0.9874 - val_loss: 0.7616 - val_accuracy: 0.8252 - 2s/epoch - 4ms/step\n",
            "Epoch 23/30\n",
            "625/625 - 2s - loss: 0.0385 - accuracy: 0.9893 - val_loss: 0.7932 - val_accuracy: 0.8250 - 2s/epoch - 3ms/step\n",
            "Epoch 24/30\n",
            "625/625 - 2s - loss: 0.0366 - accuracy: 0.9901 - val_loss: 0.8363 - val_accuracy: 0.8237 - 2s/epoch - 4ms/step\n",
            "Epoch 25/30\n",
            "625/625 - 3s - loss: 0.0356 - accuracy: 0.9894 - val_loss: 0.8852 - val_accuracy: 0.8208 - 3s/epoch - 5ms/step\n",
            "Epoch 26/30\n",
            "625/625 - 3s - loss: 0.0323 - accuracy: 0.9908 - val_loss: 0.9082 - val_accuracy: 0.8199 - 3s/epoch - 4ms/step\n",
            "Epoch 27/30\n",
            "625/625 - 2s - loss: 0.0308 - accuracy: 0.9912 - val_loss: 0.9384 - val_accuracy: 0.8150 - 2s/epoch - 4ms/step\n",
            "Epoch 28/30\n",
            "625/625 - 2s - loss: 0.0268 - accuracy: 0.9926 - val_loss: 0.9837 - val_accuracy: 0.8170 - 2s/epoch - 4ms/step\n",
            "Epoch 29/30\n",
            "625/625 - 2s - loss: 0.0245 - accuracy: 0.9940 - val_loss: 1.0216 - val_accuracy: 0.8125 - 2s/epoch - 4ms/step\n",
            "Epoch 30/30\n",
            "625/625 - 3s - loss: 0.0244 - accuracy: 0.9934 - val_loss: 1.0637 - val_accuracy: 0.8126 - 3s/epoch - 4ms/step\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "history = model.fit(training_padded, training_labels, epochs=num_epochs,\n",
        "                    validation_data=(testing_padded, testing_labels), verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7LGMoRzMt6A",
        "outputId": "49897826-5a39-47de-bf47-f7d33c25f0ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 344ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1.01818964e-01],\n",
              "       [3.86433298e-04],\n",
              "       [7.61609524e-04],\n",
              "       [1.16263074e-03],\n",
              "       [7.33894646e-01],\n",
              "       [3.58694728e-04],\n",
              "       [3.18806196e-05],\n",
              "       [4.51463020e-05],\n",
              "       [1.20013028e-01],\n",
              "       [6.93548373e-06],\n",
              "       [9.89354014e-01],\n",
              "       [1.97016388e-01],\n",
              "       [3.03525576e-05],\n",
              "       [1.29536265e-05],\n",
              "       [1.30575048e-04],\n",
              "       [2.67289276e-03],\n",
              "       [7.96675275e-04]], dtype=float32)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentences = [\n",
        "    \"Congratulations on being five minutes early. You're a real hero.\",\n",
        "    \"I love spending time with my friends and family.\",\n",
        "    \"Sure, because I absolutely love spending my weekends doing chores.\",\n",
        "    \"The weather is so nice today, perfect for a picnic.\",\n",
        "    \"Oh, great. Another Monday. Just what I needed.\",\n",
        "    \"I enjoy going for a walk in the park on a sunny day.\",\n",
        "    \"Wow, your brilliant plan worked out perfectly, didn't it?\",\n",
        "    \"I appreciate your help with the project; it made a big difference.\",\n",
        "    \"Oh, wonderful! More paperwork to make our lives even more exciting.\",\n",
        "    \"I'm really looking forward to the weekend getaway.\",\n",
        "    \"Well, that was a fantastic idea. I can't believe no one else thought of it.\",\n",
        "    \"Spending time with loved ones is truly the best part of life.\",\n",
        "    \"Brilliant move, parking your car in the middle of the road.\",\n",
        "    \"I'm grateful for the support of my colleagues at work.\",\n",
        "    \"Oh, you're the expert on everything, aren't you?\",\n",
        "    \"I can't wait to try that new restaurant everyone's talking about.\",\n",
        "    \"Gee, thanks for the unsolicited advice. I couldn't survive without it.\",\n",
        "]\n",
        "\n",
        "sentence_seq = tokenizer.texts_to_sequences(sentences)\n",
        "padded = pad_sequences(sentence_seq, maxlen=MAX_LENGTH, padding=PADDING_TYPE,\n",
        "                       truncating=TRUNC_TYPE)\n",
        "model.predict(padded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z2qckZ3Pt-d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
